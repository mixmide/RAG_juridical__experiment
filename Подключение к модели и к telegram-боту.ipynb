{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de43374d-ea7b-4d21-90ab-fb235459ee33",
   "metadata": {},
   "source": [
    "# Подключение к модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefde0b-fe4b-4dd8-82af-813f7c82f3a4",
   "metadata": {},
   "source": [
    "##### Данный этап выполнялся локально на ПК через llama.cpp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3603bdc-7147-4c75-a310-70058bac8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка нужных библиотек\n",
    "!pip install langchain faiss-cpu sentence-transformers requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f446b46-b857-4dd2-a162-931e1885818f",
   "metadata": {},
   "source": [
    "#### Эмбеддинг-модель: intfloat/multilingual-e5-large\n",
    "\n",
    "\n",
    "#### LLM: yandex/YandexGPT-5-Lite-8B-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef69a9-18ea-4155-b5b4-251b0f7de937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "DEADLINE_SIMILARITY = 0.95      # ограничение на близость фрагментов документов (показатель высокий из-за особенностей эмбеддинг-модели)\n",
    "\n",
    "# Инициализируем модель встраивания\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "# Загружаем FAISS индекс\n",
    "db = FAISS.load_local(\n",
    "    r\"C:\\Users\\zvere\\Downloads\\faiss_index_cosine\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Инициализируем токенизатор\n",
    "MODEL_NAME = \"yandex/YandexGPT-5-Lite-8B-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# URL сервера LLM\n",
    "LLM_SERVER_URL = \"http://localhost:8080/completion\"\n",
    "\n",
    "# Функция для создания промпта\n",
    "def create_prompt(query, context=None, history=None):\n",
    "    messages = []\n",
    "    \n",
    "    # Добавляем историю диалога\n",
    "    if history:\n",
    "        for msg in history:\n",
    "            messages.append({\"role\": \"user\", \"content\": msg['user']})\n",
    "            if 'assistant' in msg:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": msg['assistant']})\n",
    "    \n",
    "    # Формируем основное сообщение\n",
    "    if context:\n",
    "        context_str = \"Фрагменты из документов:\\n\"\n",
    "        for i, doc in enumerate(context, 1):\n",
    "            context_str += f\"[Фрагмент {i}] Документ-источник: {doc.metadata['document']}\\nТекст: {doc.page_content}\\n[Конец фрагмента {i}]\\n\"\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Ты - **юридический ассистент**.\\n\"\n",
    "                \"**Следуй этим шагам для ответа**:\\n\"\n",
    "                \"1. Проанализируй предоставленные фрагменты из документов. Фрагменты могут быть обрывистыми.\\n\"\n",
    "                \"2. Представь, что я не предоставлял тебе предоставленные фрагменты, но ты их изучал.\\n\"\n",
    "                \"3. Если фрагменты содержат релевантную информацию, используй её для ответа! Сочетай информацию из них со своими знаниями.\\n\"\n",
    "                \"4. Указывай в ответе название документа-источника, если это законодательный документ.\\n\"\n",
    "                \"5. Если фрагменты не содержат релевантной информации или совсем не относятся к вопросу, отвечай на основе своих знаний.\\n\"\n",
    "                \"6. Отвечай подробно, чётко и профессионально по сути вопроса.\\n\"\n",
    "                \"7. Если вопрос не юридический, используй дружелюбный стиль, но оставайся профессиональным.\\n\"\n",
    "                \"8. Не используй в ответе формат markdown, пиши обычным текстом.\\n\\n\"\n",
    "                f\"{context_str}\\n**Вопрос**: {query}\"\n",
    "            )\n",
    "        })\n",
    "    else:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Ты - **юридический ассистент**. \"\n",
    "                \"Отвечай на вопрос максимально чётко и профессионально, даже если это не юридический вопрос, \"\n",
    "                \"используя дружелюбный стиль. Не используй в ответе формат markdown, пиши обычным текстом.\\n\\n\"\n",
    "                f\"**Вопрос**: {query}\"\n",
    "            )\n",
    "        })\n",
    "    \n",
    "    # Применяем chat template\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Функция для генерации ответа\n",
    "def generate_response(query, user_chat_id, threshold=DEADLINE_SIMILARITY, top_k=3):\n",
    "    try:\n",
    "        # Получаем историю диалога для пользователя\n",
    "        history = user_dialog_history.get(user_chat_id, [])\n",
    "        \n",
    "        # Ищем топ-k чанков с их оценками схожести\n",
    "        results = db.similarity_search_with_score(query, k=top_k)\n",
    "\n",
    "        # Печатаем все найденные чанки и их значения схожести\n",
    "        print(\"Найденные релевантные чанки:\")\n",
    "        for i, (doc, l2_distance) in enumerate(results, 1):\n",
    "            cosine_sim = 1 - (l2_distance ** 2) / 2\n",
    "            print(f\"Чанк {i}:\")\n",
    "            print(f\"  Текст: {doc.page_content}\")\n",
    "            print(f\"  Источник: {doc.metadata['document']}\")\n",
    "            print(f\"  Косинусное сходство: {cosine_sim:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Проверяем релевантность лучшего чанка\n",
    "        context = None\n",
    "        if results:\n",
    "            relevant_chunks = [res[0] for res in results if (1 - (res[1] ** 2) / 2) >= threshold]\n",
    "            if relevant_chunks:\n",
    "                context = relevant_chunks\n",
    "                print(f\"Контекст используется (лучшее косинусное сходство: {(1 - (results[0][1] ** 2) / 2):.4f})\")\n",
    "            else:\n",
    "                print(\"Контекст не используется (ни один чанк не прошёл порог релевантности)\")\n",
    "        \n",
    "        # Формируем промпт с историей\n",
    "        prompt = create_prompt(query, context, history)\n",
    "        \n",
    "        # Выводим промпт для отладки\n",
    "        print(\"Окончательный промпт, отправленный в модель:\")\n",
    "        print(prompt)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Отправляем запрос к LLM\n",
    "        response = requests.post(LLM_SERVER_URL, json={\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 1024,\n",
    "            \"temperature\": 0.3,\n",
    "            \"stop\": [\"</s>\"]\n",
    "        })\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Удаляем специальные токены из ответа\n",
    "            answer = response.json()[\"content\"].replace(\"[NL]\", \"\\n\").replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\n",
    "            print(answer)\n",
    "            \n",
    "            # Обновляем историю диалога (если сообщений >= 10)\n",
    "            if len(history) >= 10:\n",
    "                history.pop(0)  # Удаляем самое старое сообщение\n",
    "            history.append({\"user\": query, \"assistant\": answer})\n",
    "            user_dialog_history[user_chat_id] = history\n",
    "            \n",
    "            return answer\n",
    "        else:\n",
    "            print(f\"Ошибка при обращении к серверу LLM: {response.status_code}\")\n",
    "            return f\"Ошибка при обращении к серверу LLM: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "        return f\"Ошибка: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7ffa-8af2-4083-8b83-696fce779a75",
   "metadata": {},
   "source": [
    "# Подключение к telegram-боту"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9bd239-ddba-40bd-b151-37b876d4565e",
   "metadata": {},
   "source": [
    "**Замечание**: в боте также реализована возможность диалога с реальным человеком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e55fa8-6012-4f33-bd9e-5c05d02d72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка нужных библиотек\n",
    "!pip install python-telegram-bot nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9e506-cf03-435e-806d-d47601eb8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import requests\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from telegram import Update\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters\n",
    "import re\n",
    "\n",
    "user_dialog_history = {}  # {user_chat_id: [{\"user\": \"вопрос\", \"assistant\": \"ответ\"}, ...]}\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Конфигурация специалиста - ЗАМЕНИТЕ НА РЕАЛЬНЫЙ CHAT_ID СПЕЦИАЛИСТА!\n",
    "SPECIALIST_CHAT_ID = \"123456789\"\n",
    "\n",
    "# Глобальное хранилище для консультаций\n",
    "active_consultations = {}  # {user_chat_id: specialist_chat_id}\n",
    "user_info_db = {}  # {user_chat_id: {\"name\": str, \"username\": str}}\n",
    "\n",
    "# для команды /start\n",
    "async def start(update: Update, context):\n",
    "    context.user_data['in_consultation'] = False\n",
    "    await update.message.reply_text(\n",
    "        \"👋 Здравствуйте! Я Ваш личный юридический нейроассистент. Задайте мне вопрос!\\n\"\n",
    "        \"📞 Для консультации со специалистом используйте /consult\\n\"\n",
    "        \"🆕 Чтобы начать новый диалог со мной - /newdialog\\n\"\n",
    "        \"❗ Бот работает в экспериментальном режиме, и его функционирование происходит локально на ноутбуке одного из авторов проекта, из-за чего также могут быть небольшие задержки в получении ответов. Просим проявить терпение! Ответы вне консультаций с экспертом генерируются ИИ. Проверяйте важную информацию.\"\n",
    "    )\n",
    "\n",
    "# для команды /consult\n",
    "async def start_consultation(update: Update, context):\n",
    "    user_chat_id = update.message.chat_id\n",
    "    user = update.message.from_user\n",
    "    \n",
    "    # Проверяем, не активна ли уже консультация\n",
    "    if context.user_data.get('in_consultation', False):\n",
    "        await update.message.reply_text(\"❗ У вас уже активна консультация со специалистом.\")\n",
    "        return\n",
    "    \n",
    "    # Сохраняем информацию о пользователе\n",
    "    user_name = user.first_name + (\" \" + user.last_name if user.last_name else \"\")\n",
    "    user_info_db[user_chat_id] = {\n",
    "        \"name\": user_name,\n",
    "        \"username\": user.username if user.username else \"не указан\"\n",
    "    }\n",
    "    \n",
    "    # Устанавливаем флаг консультации\n",
    "    context.user_data['in_consultation'] = True\n",
    "    \n",
    "    try:\n",
    "        # Сохраняем связь пользователь-специалист\n",
    "        active_consultations[user_chat_id] = SPECIALIST_CHAT_ID\n",
    "        \n",
    "        # Уведомляем пользователя\n",
    "        await update.message.reply_text(\n",
    "            \"✅ Вы подключены к специалисту. Задайте ваш вопрос, \"\n",
    "            \"и он ответит в ближайшее время.\\n\\n\"\n",
    "            \"🔸 Для возврата к боту используйте /newdialog\"\n",
    "        )\n",
    "        \n",
    "        # Уведомляем специалиста\n",
    "        await context.bot.send_message(\n",
    "            chat_id=SPECIALIST_CHAT_ID,\n",
    "            text=f\"🔔 НОВАЯ КОНСУЛЬТАЦИЯ 🔔\\n\"\n",
    "                 #f\"👤 Пользователь: {user_name}\\n\"\n",
    "                 #f\"📱 Username: @{user_info_db[user_chat_id]['username']}\\n\"\n",
    "                 f\"🆔 ID: {user_chat_id}\\n\\n\"\n",
    "                 f\"✉️ Чтобы ответить, введите:\\n\"\n",
    "                 f\"   /to_{user_chat_id} Ваш ответ\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при подключении к специалисту: {e}\")\n",
    "        await update.message.reply_text(\n",
    "            \"❌ Не удалось подключиться к специалисту. \"\n",
    "            \"Пожалуйста, попробуйте позже или свяжитесь другим способом.\"\n",
    "        )\n",
    "        context.user_data['in_consultation'] = False\n",
    "        if user_chat_id in active_consultations:\n",
    "            del active_consultations[user_chat_id]\n",
    "\n",
    "# для команды /newdialog\n",
    "async def new_dialog(update: Update, context):\n",
    "    user_chat_id = update.message.chat_id\n",
    "    \n",
    "    if context.user_data.get('in_consultation', False):\n",
    "        # Завершаем консультацию\n",
    "        context.user_data['in_consultation'] = False\n",
    "        \n",
    "        # Уведомляем специалиста\n",
    "        if user_chat_id in active_consultations:\n",
    "            try:\n",
    "                await context.bot.send_message(\n",
    "                    chat_id=active_consultations[user_chat_id],\n",
    "                    text=f\"🔴 КОНСУЛЬТАЦИЯ ЗАВЕРШЕНА 🔴\\n\"\n",
    "                         f\"Пользователь: {user_info_db[user_chat_id]['name']}\\n\"\n",
    "                         f\"ID: {user_chat_id}\"\n",
    "                )\n",
    "                # Удаляем из активных консультаций\n",
    "                del active_consultations[user_chat_id]\n",
    "                if user_chat_id in user_info_db:\n",
    "                    del user_info_db[user_chat_id]\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка уведомления специалиста: {e}\")\n",
    "        \n",
    "        await update.message.reply_text(\n",
    "            \"🗣️ Консультация завершена. Теперь вы общаетесь с ботом.\\n\"\n",
    "            \"Задайте ваш юридический вопрос!\"\n",
    "        )\n",
    "    else:\n",
    "        # Очищаем историю диалога с моделью\n",
    "        if user_chat_id in user_dialog_history:\n",
    "            del user_dialog_history[user_chat_id]\n",
    "        await update.message.reply_text(\"🆕 Новый диалог начат. История очищена. Задайте Ваш вопрос.\")\n",
    "\n",
    "# Обработчик для сообщений от специалиста\n",
    "async def handle_specialist_message(update: Update, context):\n",
    "    specialist_chat_id = update.message.chat_id\n",
    "    message_text = update.message.text\n",
    "    \n",
    "    # Проверяем команду ответа пользователю\n",
    "    if message_text.startswith('/to_'):\n",
    "        match = re.match(r'/to_(\\d+)\\s+(.*)', message_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                user_chat_id = int(match.group(1))\n",
    "                answer_text = match.group(2).strip()\n",
    "                \n",
    "                # Проверяем активность консультации\n",
    "                if user_chat_id in active_consultations:\n",
    "                    # Пересылаем сообщение пользователю\n",
    "                    await context.bot.send_message(\n",
    "                        chat_id=user_chat_id,\n",
    "                        text=f\"👨‍⚖️ Ответ от специалиста:\\n\\n{answer_text}\"\n",
    "                    )\n",
    "                    # Подтверждаем специалисту\n",
    "                    await update.message.reply_text(f\"✅ Ответ отправлен пользователю {user_info_db[user_chat_id]['name']}\")\n",
    "                else:\n",
    "                    await update.message.reply_text(\"❌ Консультация с этим пользователем не активна или завершена.\")\n",
    "            except (ValueError, IndexError):\n",
    "                await update.message.reply_text(\"❌ Неверный формат команды. Используйте: /to_123456789 Ваш ответ\")\n",
    "        else:\n",
    "            await update.message.reply_text(\"❌ Неверный формат команды. Используйте: /to_123456789 Ваш ответ\")\n",
    "    \n",
    "    # Обработка других команд специалиста\n",
    "    elif message_text.startswith('/list'):\n",
    "        # Показать активные консультации\n",
    "        if active_consultations:\n",
    "            response = \"📋 Активные консультации:\\n\\n\"\n",
    "            for user_id, spec_id in active_consultations.items():\n",
    "                if spec_id == specialist_chat_id:\n",
    "                    user_info = user_info_db.get(user_id, {\"name\": \"Неизвестный\", \"username\": \"нет\"})\n",
    "                    response += f\"👤 {user_info['name']} (@{user_info['username']})\\n🆔 ID: {user_id}\\n\\n\"\n",
    "            await update.message.reply_text(response)\n",
    "        else:\n",
    "            await update.message.reply_text(\"ℹ️ Нет активных консультаций\")\n",
    "    \n",
    "    elif message_text.startswith('/help'):\n",
    "        # Справка по командам\n",
    "        help_text = (\n",
    "            \"🛠️ Доступные команды:\\n\\n\"\n",
    "            \"/to_123456789 [текст] - Ответить пользователю с указанным ID\\n\"\n",
    "            \"/list - Показать активные консультации\\n\"\n",
    "            \"/help - Эта справка\"\n",
    "        )\n",
    "        await update.message.reply_text(help_text)\n",
    "    \n",
    "    else:\n",
    "        # Обычное сообщение без команды\n",
    "        if active_consultations:\n",
    "            await update.message.reply_text(\n",
    "                \"ℹ️ Пожалуйста, используйте команды для работы:\\n\"\n",
    "                \"/help - показать справку\\n\"\n",
    "                \"/list - активные консультации\"\n",
    "            )\n",
    "        else:\n",
    "            await update.message.reply_text(\"ℹ️ Нет активных консультаций. Ожидайте новых запросов.\")\n",
    "\n",
    "# Обработчик сообщений от пользователей\n",
    "async def handle_message(update: Update, context):\n",
    "    user_chat_id = update.message.chat_id\n",
    "    message_text = update.message.text\n",
    "    \n",
    "    # Игнорируем команды\n",
    "    if message_text.startswith('/'):\n",
    "        return\n",
    "    \n",
    "    if context.user_data.get('in_consultation', False):\n",
    "        if user_chat_id in active_consultations:\n",
    "            try:\n",
    "                # Пересылаем сообщение специалисту\n",
    "                await context.bot.send_message(\n",
    "                    chat_id=active_consultations[user_chat_id],\n",
    "                    text=f\"✉️ Сообщение от {user_info_db[user_chat_id]['name']} (@{user_info_db[user_chat_id]['username']})\\n\"\n",
    "                         f\"🆔 ID: {user_chat_id}\\n\\n\"\n",
    "                         f\"{message_text}\"\n",
    "                )\n",
    "                await update.message.reply_text(\"✅ Ваше сообщение передано специалисту. Ожидайте ответа.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка пересылки специалисту: {e}\")\n",
    "                await update.message.reply_text(\n",
    "                    \"❌ Не удалось отправить сообщение специалисту. \"\n",
    "                    \"Попробуйте позже или завершите консультацию /newdialog\"\n",
    "                )\n",
    "        else:\n",
    "            await update.message.reply_text(\n",
    "                \"⚠️ Сессия консультации не активна. Используйте /consult для подключения.\"\n",
    "            )\n",
    "    else:\n",
    "        # Создаем задачу для периодической отправки индикатора \"печатает\"\n",
    "        typing_task = asyncio.create_task(\n",
    "            send_continuous_typing(context.bot, user_chat_id)\n",
    "        )\n",
    "        \n",
    "        # Создаем задачу для генерации ответа\n",
    "        generate_task = asyncio.create_task(\n",
    "            generate_response_async(message_text, user_chat_id)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        try: #прямое ожидание ответа от модели\n",
    "            answer = await generate_task\n",
    "            await update.message.reply_text(answer)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при генерации ответа: {e}\")\n",
    "            await update.message.reply_text(\"⚠️ Произошла ошибка при обработке вашего запроса. Пожалуйста, попробуйте еще раз.\")\n",
    "        finally:\n",
    "            # Останавливаем все задачи\n",
    "            typing_task.cancel()\n",
    "            try:\n",
    "                await typing_task\n",
    "            except asyncio.CancelledError:\n",
    "                pass\n",
    "\n",
    "async def generate_response_async(message_text, user_chat_id):\n",
    "    \"\"\"Асинхронная обертка для generate_response\"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    return await loop.run_in_executor(\n",
    "        None, \n",
    "        generate_response, \n",
    "        message_text, \n",
    "        user_chat_id\n",
    "    )\n",
    "\n",
    "async def send_continuous_typing(bot, chat_id):\n",
    "    \"\"\"Периодически отправляет индикатор 'печатает' до отмены задачи\"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            await bot.send_chat_action(chat_id=chat_id, action=\"typing\")\n",
    "            await asyncio.sleep(3)  # Отправляем каждые 3 секунды\n",
    "    except asyncio.CancelledError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при отправке индикатора печати: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MAIN\n",
    "if __name__ == '__main__':\n",
    "    TELEGRAM_TOKEN = \"token\" # ЗАМЕНИТЕ НА токен бота\n",
    "    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()\n",
    "    \n",
    "    app.add_handler(CommandHandler(\"start\", start))\n",
    "    app.add_handler(CommandHandler(\"consult\", start_consultation))\n",
    "    app.add_handler(CommandHandler(\"newdialog\", new_dialog))\n",
    "    \n",
    "    # Обработчики сообщений от пользователей\n",
    "    app.add_handler(MessageHandler(\n",
    "        filters.TEXT & ~filters.COMMAND,\n",
    "        handle_message\n",
    "    ))\n",
    "    \n",
    "    # Обработчик для специалиста\n",
    "    app.add_handler(MessageHandler(\n",
    "        filters.TEXT & filters.Chat(chat_id=int(SPECIALIST_CHAT_ID)),\n",
    "        handle_specialist_message\n",
    "    ))\n",
    "    \n",
    "    print(\"Бот запущен...\")\n",
    "    app.run_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c46fd3-1968-4d88-b6a9-f9b11c6bc61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
